# Описание набора данных для классификации фруктов

## Задача

Задача проекта - классификация изображений фруктов на три класса:
- **Apple** (Яблоко)
- **Kiwi** (Киви)
- **Mandarin** (Мандарин)

Это задача классификации изображений (image classification), которая решается с помощью сверточных нейронных сетей (CNN) с использованием transfer learning.

## Метод сбора данных

Все изображения были собраны самостоятельно из личных фотографий и веб-источников (с соблюдением авторских прав для учебных целей). Изображения были отобраны таким образом, чтобы обеспечить:
- Разнообразие условий съемки (освещение, фон, угол)
- Разные стадии зрелости фруктов
- Различные размеры и формы объектов
- Естественные вариации цвета и текстуры

## Структура данных

### Исходные данные (`data/raw/`)
- **apple/**: 70 изображений яблок
- **kiwi/**: 70 изображений киви
- **mandarin/**: 70 изображений мандаринов

**Всего**: 210 изображений

### Формат данных
- Формат файлов: `.webp`, `.jpg`, `.jpeg`, `.png`
- Разрешение: различное (варьируется)
- Цветовое пространство: RGB

## Предобработка данных

Данные обрабатываются скриптом `data_preprocessing.py`, который выполняет следующие шаги:

### 1. Валидация изображений
- Проверка целостности файлов
- Верификация формата изображений
- Удаление поврежденных файлов

### 2. Разделение данных
Данные автоматически разделяются на три набора:
- **Train (70%)**: ~147 изображений - для обучения модели
- **Val (15%)**: ~32 изображения - для валидации и выбора лучшей модели
- **Test (15%)**: ~31 изображение - для финальной оценки модели

Разделение выполняется с фиксированным random seed (42) для обеспечения воспроизводимости.

### 3. Трансформации для обучения

**Для обучающего набора (train):**
- Resize до 224x224 пикселей
- RandomHorizontalFlip (p=0.5) - случайное зеркальное отражение
- RandomRotation (degrees=15) - случайный поворот до 15 градусов
- ColorJitter (brightness=0.2, contrast=0.2, saturation=0.2) - случайные изменения яркости, контраста и насыщенности
- Normalize с mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] (ImageNet статистика)

**Для валидационного и тестового наборов (val/test):**
- Resize до 224x224 пикселей
- Normalize с теми же параметрами, что и для train

### 4. Нормализация

Изображения нормализуются с использованием статистики ImageNet:
- Mean: [0.485, 0.456, 0.406] (RGB каналы)
- Std: [0.229, 0.224, 0.225] (RGB каналы)

Это необходимо для совместимости с предобученными моделями из библиотеки `timm`, которые обучены на ImageNet.

## Обработанные данные (`data/processed/`)

После предобработки данные сохраняются в структурированном виде:
```
data/processed/
├── train/
│   ├── apple/
│   ├── kiwi/
│   └── mandarin/
├── val/
│   ├── apple/
│   ├── kiwi/
│   └── mandarin/
└── test/
    ├── apple/
    ├── kiwi/
    └── mandarin/
```

Также создается файл `dataset_info.csv` с метаданными о разделении:
- Пути к исходным файлам
- Пути к обработанным файлам
- Класс изображения
- Принадлежность к набору (train/val/test)

## Использование данных

Данные загружаются в модель через `FruitDataset` класс в `train.py`, который:
- Загружает изображения из соответствующих папок
- Применяет трансформации
- Возвращает пары (изображение, метка класса)

## Характеристики набора данных

- **Количество классов**: 3
- **Изображений на класс**: 70
- **Общее количество**: 210
- **Размер изображений после обработки**: 224x224x3
- **Балансировка**: Сбалансированный набор (одинаковое количество изображений на класс)

## Особенности набора данных

1. **Разнообразие**: Изображения показывают фрукты в различных условиях
2. **Естественность**: Реальные условия съемки, не студийные
3. **Качество**: Все изображения проверены на целостность и валидность

